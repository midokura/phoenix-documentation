"use strict";(globalThis.webpackChunkfoo=globalThis.webpackChunkfoo||[]).push([[589],{2386(e,n,a){a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>i});const s=JSON.parse('{"id":"service-operator/CEPH_SETUP","title":"Setup Ceph - Generic","description":"Installing Ceph cluster on bare-metal nodes.","source":"@site/versioned_docs/version-v1.6/service-operator/CEPH_SETUP.md","sourceDirName":"service-operator","slug":"/service-operator/CEPH_SETUP","permalink":"/phoenix-documentation/docs/service-operator/CEPH_SETUP","draft":false,"unlisted":false,"tags":[],"version":"v1.6","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Service Operator Documentation","permalink":"/phoenix-documentation/docs/service-operator/intro"},"next":{"title":"Deployment Scripts","permalink":"/phoenix-documentation/docs/service-operator/DEPLOYMENT"}}');var t=a(4848),r=a(8453);const o={},d="Setup Ceph - Generic",c={},i=[{value:"You need to know:",id:"you-need-to-know",level:3},{value:"Installation",id:"installation",level:2},{value:"1. Connect to the main ceph node with",id:"1-connect-to-the-main-ceph-node-with",level:3},{value:"2. Install cephadm package",id:"2-install-cephadm-package",level:3},{value:"3. Generate a uuid",id:"3-generate-a-uuid",level:3},{value:"4. Bootstrap 1st node in the cluster",id:"4-bootstrap-1st-node-in-the-cluster",level:3},{value:"5. Access Ceph Dashboard",id:"5-access-ceph-dashboard",level:3},{value:"6. Inject Ceph admin public SSH key to the remaining nodes",id:"6-inject-ceph-admin-public-ssh-key-to-the-remaining-nodes",level:3},{value:"7. Add remaining nodes, directly from 1st node and set them as admin nodes as well",id:"7-add-remaining-nodes-directly-from-1st-node-and-set-them-as-admin-nodes-as-well",level:3},{value:"8. Zap (erase/remove) the disks before adding osd",id:"8-zap-eraseremove-the-disks-before-adding-osd",level:3},{value:"9. Start adding dedicated disk devices to the cluster",id:"9-start-adding-dedicated-disk-devices-to-the-cluster",level:3},{value:"10. Start rados gateway with:",id:"10-start-rados-gateway-with",level:3},{value:"11. Create the rados gateway user:",id:"11-create-the-rados-gateway-user",level:3},{value:"a. Write down the access and secret keys",id:"a-write-down-the-access-and-secret-keys",level:4},{value:"b. Update inventory.yml rgw_auth.access_key and rgw_auth.secret_key by encrypting them with:",id:"b-update-inventoryyml-rgw_authaccess_key-and-rgw_authsecret_key-by-encrypting-them-with",level:4},{value:"12. After Openstack configuration have been generated, come back to cephadm and run:",id:"12-after-openstack-configuration-have-been-generated-come-back-to-cephadm-and-run",level:3},{value:"Configuration and Usage",id:"configuration-and-usage",level:2},{value:"1. Create a pool for images:",id:"1-create-a-pool-for-images",level:3},{value:"2. Save the keyrings directory",id:"2-save-the-keyrings-directory",level:3},{value:"3. Enable rbd for the pools",id:"3-enable-rbd-for-the-pools",level:3}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"setup-ceph---generic",children:"Setup Ceph - Generic"})}),"\n",(0,t.jsx)(n.p,{children:"Installing Ceph cluster on bare-metal nodes."}),"\n",(0,t.jsx)(n.p,{children:"This process guides through installing Ceph cluster on bare-metal nodes, using podman as an orchestration manager. This deployment method is officially recommended by upstream."}),"\n",(0,t.jsx)(n.h3,{id:"you-need-to-know",children:"You need to know:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:'"OS ip address"'}),": We will use env var ",(0,t.jsx)(n.code,{children:"OS_IP_ADDRESS_X"})," in the guide for each node where X is the node number (1-3). It should be something like ",(0,t.jsx)(n.code,{children:"192.168.6.204"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:'"OS host"'}),": We will use env var ",(0,t.jsx)(n.code,{children:"HOSTNAME_X"})," in the guide for each node where X is the node number. It should be the host name of each server."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:'"Cluster network subnet"'}),": We will use env var ",(0,t.jsx)(n.code,{children:"CLUSTER_SUBNET"})," in the guide. It should be something like ",(0,t.jsx)(n.code,{children:"172.28.6.0/24"})]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,t.jsx)(n.h3,{id:"1-connect-to-the-main-ceph-node-with",children:"1. Connect to the main ceph node with"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"ssh -A ubuntu@$OS_IP_ADDRESS_1\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-install-cephadm-package",children:"2. Install cephadm package"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"apt install -y cephadm\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-generate-a-uuid",children:"3. Generate a uuid"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'UUID="$(uuidgen)"\n'})}),"\n",(0,t.jsx)(n.h3,{id:"4-bootstrap-1st-node-in-the-cluster",children:"4. Bootstrap 1st node in the cluster"}),"\n",(0,t.jsxs)(n.p,{children:["(FSID can be generated using ",(0,t.jsx)(n.code,{children:"uuidgen"}),")"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cephadm bootstrap --mon-ip $OS_IP_ADDRESS_1 --cluster-network $CLUSTER_SUBNET --fsid $UUID\n"})}),"\n",(0,t.jsx)(n.h3,{id:"5-access-ceph-dashboard",children:"5. Access Ceph Dashboard"}),"\n",(0,t.jsx)(n.p,{children:"From the output get the default Ceph Dashboard address, username and password, access it and update the password."}),"\n",(0,t.jsx)(n.h3,{id:"6-inject-ceph-admin-public-ssh-key-to-the-remaining-nodes",children:"6. Inject Ceph admin public SSH key to the remaining nodes"}),"\n",(0,t.jsxs)(n.p,{children:["Take the contents of ",(0,t.jsx)(n.code,{children:"/etc/ceph/ceph.pub"})," from the node you are bootstrapping, and add them to the root user\u2019s ",(0,t.jsx)(n.code,{children:"/root/.ssh/authorized_keys"})," file for all Ceph hosts."]}),"\n",(0,t.jsx)(n.h3,{id:"7-add-remaining-nodes-directly-from-1st-node-and-set-them-as-admin-nodes-as-well",children:"7. Add remaining nodes, directly from 1st node and set them as admin nodes as well"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo cephadm shell -- ceph orch host add $HOSTNAME_2 $OS_IP_ADDRESS_2 --labels _admin\nsudo cephadm shell -- ceph orch host add $HOSTNAME_3 $OS_IP_ADDRESS_3 --labels _admin\nsudo cephadm shell -- ceph orch host ls\n"})}),"\n",(0,t.jsx)(n.h3,{id:"8-zap-eraseremove-the-disks-before-adding-osd",children:"8. Zap (erase/remove) the disks before adding osd"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo cephadm shell\nceph orch device zap $HOSTNAME_1 /dev/sdX --force\n"})}),"\n",(0,t.jsx)(n.h3,{id:"9-start-adding-dedicated-disk-devices-to-the-cluster",children:"9. Start adding dedicated disk devices to the cluster"}),"\n",(0,t.jsxs)(n.p,{children:["Start adding dedicated disk devices to the cluster for each disk we want to use as ceph storage where ",(0,t.jsx)(n.code,{children:"/dev/sdX"})," is each disk."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo cephadm shell\nceph orch daemon add osd --method raw $HOSTNAME_1:/dev/sdX\nceph orch daemon add osd --method raw $HOSTNAME_2:/dev/sdX\nceph orch daemon add osd --method raw $HOSTNAME_3:/dev/sdX\n"})}),"\n",(0,t.jsx)(n.h3,{id:"10-start-rados-gateway-with",children:"10. Start rados gateway with:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'sudo cephadm shell\nceph orch apply rgw gateway --placement="3 $HOSTNAME_1 $HOSTNAME_2 $HOSTNAME_3" --port=8080\n'})}),"\n",(0,t.jsx)(n.p,{children:"Configure Keystone integration:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# https://docs.ceph.com/en/latest/radosgw/keystone/\n\n# As of the Queens release, Keystone solely implements the Identity API v3.\n# Support for Identity API v2.0 has been removed in Queens in favor of the Identity API v3.\n# https://docs.openstack.org/keystone/latest/contributor/http-api.html\n\nceph config set client.rgw.gateway rgw_keystone_api_version 3\nceph config set client.rgw.gateway rgw_keystone_url http://$OPENSTACK_URL:5000\nceph config set client.rgw.gateway rgw_keystone_admin_user ceph_rgw\nceph config set client.rgw.gateway rgw_keystone_admin_domain Default\nceph config set client.rgw.gateway rgw_keystone_admin_project service\n\n# disable token cache because of https://tracker.ceph.com/issues/21226\nceph config set client.rgw.gateway rgw_keystone_token_cache_size 0\n\n#ceph config set client.rgw.gateway rgw_keystone_verify_ssl false\nceph config set client.rgw.gateway rgw_enable_usage_log true # logging\n\n# https://docs.ceph.com/en/latest/radosgw/multitenancy/#swift-with-keystone\nceph config set client.rgw.gateway rgw_keystone_implicit_tenants true\n\n# options\nceph config set client.rgw.gateway rgw_swift_account_in_url false\n\n# https://docs.ceph.com/en/latest/radosgw/s3/authentication/\nceph config set client.rgw.gateway rgw_s3_auth_use_keystone true\n"})}),"\n",(0,t.jsx)(n.h3,{id:"11-create-the-rados-gateway-user",children:"11. Create the rados gateway user:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'radosgw-admin user create --uid="iaas-rgw-admin" --display-name="iaas management user for ceph object gateway admin API" --caps="users=*;buckets=*;usage=*;metadata=*"\n'})}),"\n",(0,t.jsx)(n.h4,{id:"a-write-down-the-access-and-secret-keys",children:"a. Write down the access and secret keys"}),"\n",(0,t.jsx)(n.h4,{id:"b-update-inventoryyml-rgw_authaccess_key-and-rgw_authsecret_key-by-encrypting-them-with",children:"b. Update inventory.yml rgw_auth.access_key and rgw_auth.secret_key by encrypting them with:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"ansible-vault encrypt_string --ask-vault-password $ACCESS_KEY --name access_key\nansible-vault encrypt_string --ask-vault-password $SECRET_KEY --name secret_key\n"})}),"\n",(0,t.jsx)(n.h3,{id:"12-after-openstack-configuration-have-been-generated-come-back-to-cephadm-and-run",children:"12. After Openstack configuration have been generated, come back to cephadm and run:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"sudo cephadm shell\nansible-vault view passwords.yml | grep ceph_rgw_keystone_password\nceph config set client.rgw.gateway rgw_keystone_admin_password <ceph_rgw_keystone_password from passwords.yml>\nceph orch restart rgw.gateway\n"})}),"\n",(0,t.jsx)(n.h2,{id:"configuration-and-usage",children:"Configuration and Usage"}),"\n",(0,t.jsx)(n.h3,{id:"1-create-a-pool-for-images",children:"1. Create a pool for images:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"ceph osd pool create images 32 32 replicated\nceph osd pool set images size 2\n\nceph osd pool create volumes 32 32 replicated\nceph osd pool set volumes size 2\n\nceph osd pool create vms 32 32 replicated\nceph osd pool set vms size 2\n\nceph osd pool create backups 32 32 replicated\nceph osd pool set backups size 2\n\nmkdir -p keyrings\n\nceph auth get-or-create client.cinder mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=volumes, allow rwx pool=vms, allow rx pool=images' | tr -d '\\t' > keyrings/ceph.client.cinder.keyring\necho >> keyrings/ceph.client.cinder.keyring\n\nceph auth get-or-create client.cinder-backup mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=backups' | tr -d '\\t' > keyrings/ceph.client.cinder-backup.keyring\necho >> keyrings/ceph.client.cinder-backup.keyring\n\nceph auth get-or-create client.glance mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=images' | tr -d '\\t' > keyrings/ceph.client.glance.keyring\necho >> keyrings/ceph.client.glance.keyring\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-save-the-keyrings-directory",children:"2. Save the keyrings directory"}),"\n",(0,t.jsxs)(n.p,{children:["Save the keyrings directory in a permanent location.\nYou will need them for the ",(0,t.jsx)(n.a,{href:"/phoenix-documentation/docs/service-operator/DEPLOYMENT",children:"DEPLOYMENT"})," section."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Important:"})," Remove the keyrings directory after saving them."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"rm -rf keyrings\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-enable-rbd-for-the-pools",children:"3. Enable rbd for the pools"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"ceph osd pool application enable images rbd\nceph osd pool application enable volumes rbd\nceph osd pool application enable vms rbd\nceph osd pool application enable backups rbd\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},8453(e,n,a){a.d(n,{R:()=>o,x:()=>d});var s=a(6540);const t={},r=s.createContext(t);function o(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);